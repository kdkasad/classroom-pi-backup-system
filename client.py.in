#!/usr/bin/env python3


#
#    Raspberry Pi Backup System for Classrooms - Client Script
#    Copyright (C) 2022  Kian Kasad
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License, version 3, as
#    published by the Free Software Foundation.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <https://www.gnu.org/licenses/>.
#


import argparse
import atexit
import errno
import fcntl
import json
import os
import pwd
import requests
import shutil
import socket
import subprocess
import sys
import tempfile
import time

from fcntl import LOCK_EX, LOCK_NB
from json import JSONDecodeError
from pathlib import Path
from requests.exceptions import HTTPError
from stat import S_IRUSR, S_IWUSR, S_IXUSR
from subprocess import CalledProcessError, DEVNULL


# Default IP address of the backup server if one is not provided in the stored
# configuration data
DEFAULT_SERVER_IP = 'm4_SERVER_IP'

# Port on which the backup server is serving configuration
CONFIG_SERVER_PORT = m4_HTTPD_PORT

# Port on which the backup server is listening for SSH connections
SSHD_PORT = m4_SSHD_PORT

# Location of drop-in configuration file for backup.timer
TIMER_DROPIN_PATH = '/etc/systemd/system/backup.timer.d/00-times.conf'

# Default location for the backup client's lock file. If $RUNTIME_DIRECTORY
# is set, the file will be placed in that directory instead.
DEFAULT_LOCK_FILE_PATH = '/var/run/backup_client.lock'

# Command to use instead of 'ssh'
rsh = 'ssh -q -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null'
SSH_KEY = '/usr/local/share/backup_client/ssh_key'

# Environment variables to run Borg with
BORG_ENV = {
    'BORG_UNKNOWN_UNENCRYPTED_REPO_ACCESS_IS_OK': 'yes',
    'BORG_RELOCATED_REPO_ACCESS_IS_OK': 'yes',
}

# Empty configuration structure.
# Must contain all the keys that might be accessed but need not contain any
# values.
DEFAULT_CONFIG = {
    'epoch': 0,
    'server': {
        'host': DEFAULT_SERVER_IP,
        'httpd_port': CONFIG_SERVER_PORT,
        'sshd_port': SSHD_PORT,
    },
    'updates': [
        {
            'epoch': 0,
            'script': 'updates/00-no_op.sh',
        }
    ],
    'archive_name_format': '{now}',
    'backup_times': [
        '@before:shutdown.target'
    ],
    'backup_time_randomized_delay': '2min',
    'backup_paths': ['~/Desktop'],
    'backup_user': 'pi',
}

# When called with --resume-after-update, we store the epoch given here
skip_updates_through = 0


def die(*args, **kwargs):
    if args:
        error(*args, **kwargs)
    print('Exiting...')
    exit(1)


def log(*args, **kwargs):
    print('\x1b[1;34mInfo:\x1b[m ', end='')
    print(*args, **kwargs)


def warn(*args, **kwargs):
    print('\x1b[1;33mWarning:\x1b[m ', end='')
    print(*args, **kwargs)


def error(*args, **kwargs):
    print("\x1b[1;31mError:\x1b[m ", end='')
    print(*args, **kwargs)


def fill_struct_with_defaults(source, default):
    for key, value in default.items():
        if key not in source:
            source[key] = value
        elif isinstance(source[key], dict):
            fill_struct_with_defaults(source[key], value)
        elif isinstance(source[key], str) and not source[key]:
            source[key] = value


def time_is_valid(time):
    cmd = ['/usr/bin/systemd-analyze', 'calendar', time]
    proc = subprocess.run(cmd, stdout=DEVNULL, stderr=DEVNULL)
    return proc.returncode == 0


def apply_config(config, prev_config):
    global skip_updates_through

    # Apply updates from updates list
    current_update_epoch = max(max(
        [update['epoch'] for update in prev_config['updates']]
    ), skip_updates_through)
    latest_update_epoch = max(
        [update['epoch'] for update in config['updates']]
    )
    for i in range(current_update_epoch + 1, latest_update_epoch + 1):
        try:
            update = [update for update in config['updates']
                      if update['epoch'] == i][0]
            apply_update(config['server'], i, update['script'])
        except IndexError:
            pass

    # Set times for backup.timer
    # See systemd.timer(5) and systemd.time(7) for details
    enable_on_shutdown = False
    try:
        with open(TIMER_DROPIN_PATH, 'w') as times:
            print('[Timer]', file=times)
            # Print randomized delay setting
            # TODO: check validity using systemd-analyze
            print('RandomizedDelaySec=',
                  config['backup_time_randomized_delay'], sep='', file=times)

            # Print times
            print('OnCalendar=', file=times)
            for time in config['backup_times']:
                if time == '@shutdown':
                    enable_on_shutdown = True
                elif time_is_valid(time):
                    print('OnCalendar=', time, sep='', file=times)
                else:
                    warn(f"Time specifier '{time}' is invalid. Ignoring it...")
    except OSError as err:
        die('Failed to save trigger times to ',
            TIMER_DROPIN_PATH, ': ', err, sep='')

    # Enable/disable backup-on-shutdown.service
    cmd = [
        '/usr/bin/systemctl', '--no-ask-password',
        'enable' if enable_on_shutdown else 'disable',
        '--now',
        'backup-on-shutdown.service'
    ]
    try:
        subprocess.run(cmd, check=True, stdout=DEVNULL, stderr=DEVNULL)
    except CalledProcessError as err:
        warn('Failed to enable backup on shutdown service:', err)

    # Reload systemd
    try:
        cmd = ['/usr/bin/systemctl', '--no-ask-password', 'daemon-reload']
        subprocess.run(cmd, check=True, stdout=DEVNULL, stderr=DEVNULL)
    except CalledProcessError as err:
        warn('Failed to reload systemd:', err)
        warn('Continuing anyways...')


def apply_update(server, epoch, script_name):
    log('Attempting to apply update #', epoch, '...', sep='')
    uri = f"http://{server['host']}:{server['httpd_port']}/{script_name}"
    try:
        response = requests.get(uri)
        script = response.text
        status = subprocess.run(
            '/bin/bash', input=script, text=True, check=True)
    except CalledProcessError as err:
        die(f"Update #{epoch}'s script returned non-zero exit status {err.returncode}")
    except ConnectionError as err:
        die(f'Failed to download script for update #{epoch}:', err)
    except HTTPError as err:
        die('HTTP error:', err)


def store_config(data, path):
    try:
        with open(path, 'w') as file:
            file.write(data)
    except OSError as err:
        warn('Failed to save updated configuration:', err)


def do_backup(config, ssh_key, is_retry=False):
    global rsh, BORG_ENV

    server_ip = config['server']['host']
    sshd_port = config['server']['sshd_port']

    repo_uri = f'ssh://backup@{server_ip}:{sshd_port}/~/repos/' + '{hostname}'
    archive_path = repo_uri + '::' + config['archive_name_format']

    cmd = [
        '/usr/bin/borg',
        '--rsh', rsh,
        'create',
        '--log-json',
        '--json',
        archive_path,
        *[os.path.expanduser(path) for path in config['backup_paths']]
    ]

    # Run Borg
    proc = subprocess.run(cmd, env=BORG_ENV, capture_output=True, text=True)

    # Process log messages
    repo_doesnt_exist = False
    errors = []
    warnings = []
    for line in proc.stderr.splitlines():
        try:
            msg = json.loads(line)
        except JSONDecodeError:
            continue  # ignore non-JSON output
        if msg['levelname'] == 'ERROR':
            if msg.get('msgid', '') == 'Repository.DoesNotExist':
                repo_doesnt_exist = True
            errors.append(msg)
        elif msg['levelname'] == 'WARNING':
            warnings.append(msg)

    if proc.returncode == 0:
        # Succeeded
        log('Borg successfully created backup.')
    elif proc.returncode == 1:
        # Succeeded with warnings
        warn('Borg successfully created backup, but produced',
             len(warnings), 'warnings (listed below).')
        for msg in warnings:
            warn('borg:', msg['message'])
    elif proc.returncode == 2:
        # Failed
        if repo_doesnt_exist and not is_retry:
            warn('Backup repository does not exist. Creating new repository...')
            create_repo(repo_uri, ssh_key)
            do_backup(config, ssh_key, True)
        else:
            error('Borg failed to create backup and produced',
                  len(errors), 'errors and', len(warnings), 'warnings (listed below).')
            for msg in errors:
                error('borg:', msg['message'])
            for msg in warnings:
                warn('borg:', msg['message'])
            die()


def create_repo(uri, ssh_key):
    global rsh, BORG_ENV
    cmd = [
        '/usr/bin/borg',
        '--rsh', rsh,
        'init',
        '--log-json',
        '--encryption', 'none',
        uri
    ]

    # Run Borg
    proc = subprocess.run(cmd, env=BORG_ENV, capture_output=True, text=True)

    # Process log messages
    errors = []
    warnings = []
    for line in proc.stderr.splitlines():
        try:
            msg = json.loads(line)
        except JSONDecodeError:
            continue  # ignore non-JSON output
        if msg['levelname'] == 'ERROR':
            errors.append(msg)
        elif msg['levelname'] == 'WARNING':
            warnings.append(msg)

    # Check return code
    if proc.returncode == 0:
        # Success
        log('Successfully created repository at', uri)
    elif proc.returncode == 1:
        warn('Successfully created repository at', uri,
             'but Borg produced', len(warnings), warnings)
        for msg in warnings:
            warn('borg:', msg['message'])
    elif proc.returncode == 2:
        # Failed
        error('Borg failed to create repository and produced',
              len(warnings), 'warnings and', len(errors), 'errors (listed below).')
        for msg in warnings:
            error('borg:', msg['message'])
        for msg in errors:
            warn('borg:', msg['message'])
        die()


# Make a user-readable copy of the SSH key
def copy_ssh_key(uid, gid):
    try:
        # Create temporary key file
        (fd, tmppath) = tempfile.mkstemp()
        os.chown(fd, uid, gid)
        os.chmod(fd, S_IRUSR)

        # Delete temporary key file when program exits
        def delete_ssh_key(ssh_key):
            try:
                os.remove(ssh_key)
            except Exception as err:
                pass  # ignore
        atexit.register(delete_ssh_key, tmppath)

        # Copy contents from original key
        with open(SSH_KEY, 'rb') as src, open(fd, 'wb') as dst:
            shutil.copyfileobj(src, dst)
    except Exception as err:
        die('Failed to make copy of SSH key:', err)

    return tmppath


def get_drop_ids(user):
    try:
        if isinstance(user, int):
            uid = user
            gid = pwd.getpwuid(uid).pw_gid
        else:
            pwinfo = pwd.getpwnam(user)
            uid = pwinfo.pw_uid
            gid = pwinfo.pw_gid
    except KeyError as err:
        die('Failed to get UID/GID of target user:', err)
    return (uid, gid)


def drop_privileges_to(uid, gid):
    try:
        # Order is important
        os.environ.clear()
        os.setgroups([])
        os.setgid(gid)
        os.setuid(uid)
        os.umask(0o022)
        os.chdir(Path.home())
    except Exception as err:
        die('Failed to drop privileges:', err)


def main():
    global DEFAULT_CONFIG, rsh, DEFAULT_LOCK_FILE_PATH, skip_updates_through

    # Attempt to acquire lock file
    try:
        lockfile_path = Path(os.getenv('RUNTIME_DIRECTORY').split(':')[0])
        lockfile_path /= 'backup_client.lock'
    except:
        warn('Environment variable RUNTIME_DIRECTORY is not set. Falling back to',
             DEFAULT_LOCK_FILE_PATH, 'as lock file.')
        lockfile_path = DEFAULT_LOCK_FILE_PATH
    try:
        lockfile = open(lockfile_path, 'w')
    except OSError as err:
        die('Failed to open lock file:', err)
    try:
        fcntl.flock(lockfile, LOCK_EX | LOCK_NB)
    except OSError as err:
        if err.errno == errno.EWOULDBLOCK or err.errno == errno.EACCES:
            die(f'Cannot acquire lock on {DEFAULT_LOCK_FILE_PATH}. Is the backup client is already running?')
        else:
            die('Failed to acquire lock on ', err, '.', sep='')

    # Parse command-line arguments
    ap = argparse.ArgumentParser()
    ap.add_argument('-u', '--resume-after-update',
                    help='Skips application of updates prior to the epoch given',
                    type=int,
                    default=0)
    args = ap.parse_args()
    skip_updates_through = args.resume_after_update

    # Attempt to load stored configuration file
    try:
        state_dir = Path(os.getenv('STATE_DIRECTORY').split(':')[0])
    except:
        die("Environment variable STATE_DIRECTORY is not set")
    stored_config_path = state_dir / 'config.json'
    try:
        with open(stored_config_path, 'r') as file:
            stored_config = json.load(file)
            fill_struct_with_defaults(stored_config, DEFAULT_CONFIG)
    except FileNotFoundError:
        warn('No stored configuration file found.')
        stored_config = DEFAULT_CONFIG
    except ValueError:
        warn('Stored configuration contains invalid JSON. Ignoring it.')
        stored_config = DEFAULT_CONFIG

    # Find backup server parameters
    server_host = stored_config['server']['host']
    httpd_port = stored_config['server']['httpd_port']
    log('Backup server host:', server_host)
    log('HTTPd port:', httpd_port)

    # Fetch latest configuration from server
    uri = f'http://{server_host}:{httpd_port}/config.json'
    try:
        response = requests.get(uri)
        response.raise_for_status()
        config_json = response.text
        config = response.json()
        fill_struct_with_defaults(config, DEFAULT_CONFIG)
    except ConnectionError as err:
        die('Connection to configuration server failed:', err)
    except HTTPError as err:
        die('HTTP error:', err)
    except ValueError as err:
        die('Invalid JSON response from configuration server:', err)

    # If fetched config is newer, apply and store it
    if config['epoch'] > stored_config['epoch']:
        log('Applying new configuration...')
        apply_config(config, stored_config)
        store_config(config_json, stored_config_path)

    uid, gid = get_drop_ids(os.getenv('BACKUP_USER')
                            or config['backup_user'] or 'pi')
    ssh_key = copy_ssh_key(uid, gid)
    rsh += ' -i ' + ssh_key
    drop_privileges_to(uid, gid)
    do_backup(config, ssh_key)


if __name__ == '__main__':
    main()
